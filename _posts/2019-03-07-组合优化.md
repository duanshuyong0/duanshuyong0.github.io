

### PAPER-URL

https://arxiv.org/pdf/1611.09940.pdf

### 基于深度强化学习的组合优化问题

本文提出了一个利用神经网络和强化学习解决组合优化问题的框架。我们主要研究旅行商问题（TSP），并训练一个递归神经网络，在给定一组城市坐标的情况下，预测不同城市排列的分布。以负游程长度作为奖励信号，采用策略梯度法对电流神经网络的参数进行优化。我们将在一组训练图上学习网络参数与在个别测试图上学习网络参数进行比较。尽管计算量大，但在缺乏工程和启发式设计的情况下，神经组合优化在最多100个节点的二维欧几里德图上获得了接近最优的结果。同样的方法也适用于背包，这是另一个NP难题，它可以为200个物品的情况得到最优解。

**1）简介**

组合优化是计算机科学中的一个基本问题。一个典型的例子是旅行商问题（TSP），在给出一个图的情况下，需要搜索排列空间，以找到具有最小总边权（旅行长度）的节点的最佳序列。TSP及其变体在规划、制造、遗传学等领域有着无数的应用（参见（Applegate等人，2011年）的概述）。

即使在二维欧几里得情况下（Papadimitriou，1977），找到最佳TSP解也是NP困难的，其中节点是二维点，边缘权重是点对之间的欧几里得差。在实践中，TSP求解者依靠手工设计的启发式方法来指导他们的搜索过程，从而有效地找到有竞争力的旅游路线。尽管这些启发式方法在TSP上很好地工作，但是一旦问题语句发生轻微变化，就需要对它们进行修改。相比之下，机器学习方法有潜力通过自动发现基于训练数据的自己的启发式方法来应用于许多优化任务，因此比仅针对一个任务优化的求解器需要更少的手工工程。

虽然大多数成功的机器学习技术都属于监督学习家族，即学习从训练输入到输出的映射，但监督学习并不适用于大多数组合优化问题，因为人们无法获得最优标签。但是，可以使用验证器比较一组解决方案的质量，并向学习算法提供一些奖励反馈。因此，我们采用强化学习（RL）范式来处理组合优化问题。我们从经验上证明，即使使用最优解作为标记数据来优化监督映射，与探索不同旅行并观察其相应回报的RL代理相比，其泛化效果也相当差。

我们提出了一种利用增强学习和神经网络解决组合优化问题的框架——神经组合优化。我们考虑两种基于政策梯度的方法（Williams，1992）。第一种方法被称为RL预训练，它使用训练集来优化循环神经网络（RNN），该网络以期望的回报为目标，参数化随机策略而非解。在测试时，策略是固定的，通过贪婪的解码或采样进行推理。第二种方法称为主动搜索，不涉及预培训。

它从一个随机策略开始，在一个测试实例上迭代优化RNN参数，再次使用预期的奖励目标，同时跟踪在搜索过程中抽样的最佳解决方案。我们发现，在实践中，将RL预训练与主动搜索相结合效果最好。

在具有多达100个节点的二维欧几里德图上，神经组合优化显著优于TSP的监督学习方法（Vinyals等人，2015b），并在允许更多计算时间时获得接近最优的结果。我们通过对背包问题的相同方法的测试来说明它的灵活性，对于最多有200个物品的情况，我们得到了最佳的结果。这些结果使我们深入了解了如何将神经网络作为解决组合优化问题的通用工具，尤其是那些难以设计启发式算法的问题。

**2）前置工作**

旅行商问题是一个研究得很好的组合优化问题，对欧几里德图和非欧几里德图提出了许多精确或近似的算法。Christofides（1976）提出了一种启发式算法，包括计算最小生成树和最小权重完全匹配。在TSP的度量实例中，该算法具有多项式运行时间，并返回保证在1.5倍的最优性系数范围内的解。

最著名的TSP精确动态规划算法的复杂度为2 nn2，使其无法扩展到大型实例，比如40点。然而，最先进的TSP解算器，由于精心设计的启发式方法描述了如何有效地导航可用解空间，可以解决具有数千个节点的对称TSP实例。Concorde（Applegate et al.，2006）被广泛认为是最精确的TSP解算器之一，利用切割平面算法（Dantzig et al.，1954；Padberg&Rinaldi，1990；Applegate et al.，2003），迭代求解TSP的线性规划松弛，并结合分支和绑定方法，修剪搜索空间的部分。这可证明不包含最优解。同样，lin kernighan-helsgaun启发式（helsgaun，2000年），灵感来自lin-kernighan启发式（lin&kernighan，1973年），是对称TSP的一种最先进的近似搜索启发式，已被证明可以解决具有数百个节点的实例以达到最佳。

更通用的解决方案，如谷歌的车辆路径问题解决方案（Google，2016），解决TSP的超集，通常依赖于本地搜索算法和元启发式算法的组合。本地搜索算法在候选解决方案上应用一组指定的本地移动操作符，基于手工设计的启发式方法，如2-opt（Johnson，1990），在搜索空间中从一个解决方案导航到另一个解决方案。然后应用元启发式方法提出上坡运动并避开局部最优解。TSP及其变体的元启发式的一个流行选择是引导局部搜索（Voudouris&Tsang，1999），它通过惩罚它认为不应该出现在一个好的解决方案中的特定解决方案功能而脱离局部最小值。



将现有搜索启发式方法应用于新遇到的问题（甚至类似问题的新实例）的难度是一个众所周知的挑战，源于无免费午餐Theo-Rem（Wolpert&Macready，1997）。由于所有搜索算法在对所有问题进行平均时都具有相同的性能，因此在选择搜索算法时，必须适当地依赖先验问题以保证性能。这一挑战激发了人们对提高优化系统运行的普遍性水平的兴趣（Burke等人，2003年），并且是超启发式背后的潜在动力，即“选择或生成启发式以解决计算搜索问题的搜索方法或学习机制”。超启发式方法的目标是通过部分地抽象出选择启发式的知识密集型过程，从而比特定于问题的方法更容易使用，因为给定了一个组合问题，并且已经证明在许多任务中以优越的方式成功地结合了人类定义的启发式方法（参见（Burke等人，2013年）的一项调查）。然而，超启发式算法是在启发式算法的搜索空间上进行的，而不是在解的搜索空间上进行的，因此，它最初仍然依赖于人类创造的启发式算法。